{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from benatools.tools import BaseOptimizeBlend\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and Optimizer\n",
    "We need to define an Optimizer class, implementing the metric method. The Optimizer class extends the BaseOptimizeBlend, which has already implemented fit and predict methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer(BaseOptimizeBlend):\n",
    "    def metric(self, coef, X, y):\n",
    "        x_coef = X * coef\n",
    "        predictions = np.sum(x_coef, axis=1)\n",
    "        score = mean_squared_error(y, predictions)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is useful to define some other helper functions when dealing with complex scoring functions.  \n",
    "Another good practice is to name the oof and the submission files with the same suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_folder(folder):\n",
    "    oof = glob(folder+'/oof*.csv')\n",
    "    subs = glob(folder+'/sub*.csv')\n",
    "    oof = sorted(oof, key=lambda x: int(x[:-4].split('_')[-1]))\n",
    "    subs = sorted(subs, key=lambda x: int(x[:-4].split('_')[-1]))\n",
    "    return oof, subs\n",
    "\n",
    "def score(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Actual Training Labels\n",
    "The values the optimizer will work with are based on OOF calculations. Thus, we need to read the actual training labels in order to calculate metrics on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train labels\n",
    "LABELS = ['label_1', 'label_2']\n",
    "train = pd.read_json('train.csv')\n",
    "y_true = train[LABELS].values\n",
    "y_true.shape  # Shape should be (n_train_samples, n_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read OOF and Submission Files\n",
    "It is important to get the list of files to evaluate (both OOF and Submission files for each model), and calculate the metric on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = []\n",
    "subs = []\n",
    "\n",
    "# List all the folders to read files from\n",
    "folders = ['ensemble/rnn', 'ensemble/gnnnew']\n",
    "\n",
    "# Read all the folders\n",
    "for f in folders:\n",
    "    a,b = read_folder(f)\n",
    "    oof += a\n",
    "    subs += b\n",
    "\n",
    "# Create a Dataframe with both OOF and Submission paths for the same model\n",
    "df_data = pd.DataFrame({'oof':oof, 'subs':subs})\n",
    "\n",
    "# Calculate OOF score for each model. Important to sort each file by its row id, to make sure we compare apples with apples\n",
    "df_data['oof_score'] = df_data.apply(lambda x: score( pd.read_csv(x['oof'], encoding='utf-8', engine='c').sort_values('id')[LABELS].values, y_oof ), axis=1 )\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read OOF files and stack them into a numpy array\n",
    "oof_arr = np.stack([pd.read_csv(f, encoding='utf-8', engine='c').sort_values('id')[LABELS] for f in df_data['oof'].values])\n",
    "# Shape will be (n_estimators, n_samples, n_labels)\n",
    "oof_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of Optimizers, one for each label to optimize\n",
    "opts = [Optimizer() for i in range(y_true.shape[1])]\n",
    "\n",
    "# Run optimization process for each label\n",
    "for i, o in enumerate(opts):\n",
    "    x = oof_arr[:,:,i].T  # OOF calculated from all estimators for label i\n",
    "    o.fit(x, y_true[:,i])\n",
    "    print('Original Metric', mean_squared_error(y_true[:,i], np.mean(oof_arr[:,:,i].T, axis=1), squared=False))\n",
    "    print('Coefficients', o.get_coef())\n",
    "    print('Coefficients shape', o.get_coef().shape)\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blend\n",
    "Once the coefficients have been calculated, it is time to apply them to the submissions files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Submission files and stack them innto a numpy array\n",
    "subs_arr = np.stack([pd.read_csv(f, encoding='utf-8', engine='c').sort_values('id')[LABELS] for f in df_data['subs'].values])\n",
    "# Shape will be (n_estimators, n_samples, n_labels)\n",
    "subs_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(df_data['subs'][0], encoding='utf-8', engine='c').sort_values('id')[LABELS]\n",
    "\n",
    "# Apply coefficients to every submission file\n",
    "for i,c in enumerate(LABELS):\n",
    "    df[c] = opts[i].predict(subs_arr[:,:,i].T)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save new submission file\n",
    "df.to_csv('submission.csv', index=False)\n",
    "print('Submission saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
